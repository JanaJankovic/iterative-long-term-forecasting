{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65164431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.utils.model_utils import seed_all\n",
    "from src.utils.model_utils import get_device\n",
    "from src.utils.data_class import ModelConfig, TrainConfig, DataConfig, LatentForecasterConfig, OptimConfig\n",
    "from src.model.operations.pipeline import tabular_latent_pipeline\n",
    "from src.utils.plots import plot_forecast_simple\n",
    "from src.utils.hpo import random_search_tabular_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52629a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(s, data_cfg: DataConfig, model_cfg: ModelConfig, train_cfg: TrainConfig):\n",
    "    seed_all(s)\n",
    "    device = get_device()\n",
    "    res = tabular_latent_pipeline(data_cfg, model_cfg, train_cfg, device, './../output')\n",
    "    series = res[\"X_all\"][:, 0]\n",
    "    y_pred = res[\"y_pred\"]\n",
    "\n",
    "    plot_forecast_simple(series, y_pred, data_cfg.split_ratio[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17265e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path(\"./../data/load\")\n",
    "\n",
    "# Example: pick first file\n",
    "files = sorted([p for p in DATA.glob(\"*.csv\")])\n",
    "if not files:\n",
    "    raise SystemExit(f\"No CSVs found in {DATA}\")\n",
    "csv_path = str(files[0])\n",
    "\n",
    "seed = 42\n",
    "seed_all(seed)\n",
    "\n",
    "HORIZON = 150\n",
    "SPLIT_RATIO = (0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce23d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO search space for your TabularAutoencoder + latent 1-step forecaster setup.\n",
    "# All values are discrete; random_search_tabular_latent samples uniformly.\n",
    "\n",
    "space = {\n",
    "    # -------------------------\n",
    "    # Data / splitting\n",
    "    # -------------------------\n",
    "    \"data_cfg.split_ratio\": [\n",
    "        (0.6, 0.2, 0.2),\n",
    "        (0.7, 0.1, 0.2),\n",
    "        (0.7, 0.15, 0.15),\n",
    "        (0.8, 0.1, 0.1),\n",
    "    ],\n",
    "    \"data_cfg.horizon\": [100],\n",
    "\n",
    "    # Feature engineering\n",
    "    \"data_cfg.lags\": [\n",
    "        (1, 2, 7, 14, 30),\n",
    "        (1, 7, 14, 28),\n",
    "        (1, 2, 3, 7, 14),\n",
    "        (1, 24, 48, 72),          # if your data is hourly\n",
    "        (1, 24, 168),             # daily + weekly cycle style (hourly data)\n",
    "    ],\n",
    "    \"data_cfg.rolling_windows\": [\n",
    "        (3, 7),\n",
    "        (3, 7, 14),\n",
    "        (7, 14),\n",
    "        (14, 30),\n",
    "    ],\n",
    "\n",
    "    # -------------------------\n",
    "    # AE architecture\n",
    "    # -------------------------\n",
    "    \"model_cfg.latent_dim\": [2, 4, 8, 16, 32],\n",
    "    \"model_cfg.hidden\": [64, 128, 256],\n",
    "    \"model_cfg.layers\": [1, 2, 3],\n",
    "    \"model_cfg.activation\": [\"relu\", \"gelu\", \"tanh\"],\n",
    "    \"model_cfg.dropout\": [0.0, 0.05, 0.1, 0.2],\n",
    "\n",
    "    # VAE on/off + KL strength\n",
    "    \"model_cfg.variational\": [False, True],\n",
    "    \"model_cfg.beta_kl\": [0.0, 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3],\n",
    "\n",
    "    # If you keep VAE True, keep stability\n",
    "    \"model_cfg.latent_cfg.use_mu_not_sample\": [True],  # do not sample during forecasting\n",
    "\n",
    "    # -------------------------\n",
    "    # Latent forecaster (sklearn)\n",
    "    # -------------------------\n",
    "    \"model_cfg.latent_cfg.regressor_name\": [\n",
    "        \"linear\",\n",
    "        \"ridge\",\n",
    "        \"lasso\",\n",
    "        \"elasticnet\",\n",
    "        \"random_forest\",\n",
    "        \"extra_trees\",\n",
    "        \"xgboost\",\n",
    "    ],\n",
    "\n",
    "    # RF / ExtraTrees variants (your build_regressor should ignore unused keys)\n",
    "    \"model_cfg.latent_cfg.regressor_params\": [\n",
    "        # conservative\n",
    "        {\"n_estimators\": 200, \"random_state\": 42, \"n_jobs\": -1, \"max_depth\": None, \"min_samples_leaf\": 1},\n",
    "        {\"n_estimators\": 400, \"random_state\": 42, \"n_jobs\": -1, \"max_depth\": None, \"min_samples_leaf\": 1},\n",
    "        {\"n_estimators\": 800, \"random_state\": 42, \"n_jobs\": -1, \"max_depth\": None, \"min_samples_leaf\": 1},\n",
    "        # regularized trees to reduce fixed-point collapse\n",
    "        {\"n_estimators\": 400, \"random_state\": 42, \"n_jobs\": -1, \"max_depth\": 12, \"min_samples_leaf\": 2},\n",
    "        {\"n_estimators\": 600, \"random_state\": 42, \"n_jobs\": -1, \"max_depth\": 10, \"min_samples_leaf\": 4},\n",
    "        # more randomness\n",
    "        {\"n_estimators\": 600, \"random_state\": 42, \"n_jobs\": -1, \"max_features\": \"sqrt\", \"min_samples_leaf\": 2},\n",
    "    ],\n",
    "\n",
    "    # -------------------------\n",
    "    # AE training\n",
    "    # -------------------------\n",
    "    \"train_cfg.epochs_ae\": [10, 20, 30, 50, 80],\n",
    "    \"train_cfg.loss_fn\": [\"mse\", \"mae\"],\n",
    "    \"train_cfg.grad_clip\": [None, 0.5, 1.0, 2.0],\n",
    "    \"train_cfg.early_stop_patience\": [5, 7, 10],\n",
    "\n",
    "    # Optim\n",
    "    \"model_cfg.optim.name\": [\"adamw\", \"adam\"],\n",
    "    \"model_cfg.optim.lr\": [3e-4, 1e-3, 3e-3],\n",
    "    \"model_cfg.optim.weight_decay\": [0.0, 1e-4, 1e-3],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52776170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [15:46:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"min_samples_leaf\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m      9\u001b[0m model_cfg \u001b[38;5;241m=\u001b[39m ModelConfig(\n\u001b[0;32m     10\u001b[0m latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m     11\u001b[0m horizon\u001b[38;5;241m=\u001b[39mHORIZON,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m variational\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m train_cfg \u001b[38;5;241m=\u001b[39m TrainConfig(\n\u001b[0;32m     22\u001b[0m epochs_ae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     23\u001b[0m loss_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m early_stop_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 28\u001b[0m \u001b[43mrandom_search_tabular_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_cfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\projects\\iterative-long-term-forecasting\\src\\utils\\hpo.py:100\u001b[0m, in \u001b[0;36mrandom_search_tabular_latent\u001b[1;34m(base_seed, n_trials, space, data_cfg, model_cfg, train_cfg, out_dir, device, metric_key, minimize, verbose)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown hyperparameter key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtabular_latent_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m metrics \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m metrics:\n",
      "File \u001b[1;32m~\\Documents\\projects\\iterative-long-term-forecasting\\src\\model\\operations\\pipeline.py:51\u001b[0m, in \u001b[0;36mtabular_latent_pipeline\u001b[1;34m(data_cfg, model_cfg, train_cfg, device, out_dir, verbose)\u001b[0m\n\u001b[0;32m     48\u001b[0m n_train \u001b[38;5;241m=\u001b[39m meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_train\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     49\u001b[0m horizon \u001b[38;5;241m=\u001b[39m data_cfg\u001b[38;5;241m.\u001b[39mhorizon\n\u001b[1;32m---> 51\u001b[0m latent_meta \u001b[38;5;241m=\u001b[39m \u001b[43mlatent_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m X_hat_s \u001b[38;5;241m=\u001b[39m latent_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_hat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     53\u001b[0m X_hat \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(X_hat_s)\n",
      "File \u001b[1;32m~\\Documents\\projects\\iterative-long-term-forecasting\\src\\model\\architecture\\lantent.py:96\u001b[0m, in \u001b[0;36mTabularLatent.forecast\u001b[1;34m(self, X_all, n_train, horizon, device)\u001b[0m\n\u001b[0;32m     94\u001b[0m effective_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(horizon, \u001b[38;5;28mlen\u001b[39m(Z_test))\n\u001b[0;32m     95\u001b[0m z_start \u001b[38;5;241m=\u001b[39m Z_train[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 96\u001b[0m Z_hat \u001b[38;5;241m=\u001b[39m \u001b[43miterative_forecast_latent_1step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecaster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meffective_h\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m X_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_numpy(Z_hat, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (effective_h, F)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m X_hat[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# predicted series (in same space as X_all)\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\projects\\iterative-long-term-forecasting\\src\\model\\architecture\\lantent.py:23\u001b[0m, in \u001b[0;36miterative_forecast_latent_1step\u001b[1;34m(forecaster, z_start, n_steps)\u001b[0m\n\u001b[0;32m     21\u001b[0m out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps):\n\u001b[1;32m---> 23\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1,L)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     out\u001b[38;5;241m.\u001b[39mappend(z\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(out)\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\sklearn\\multioutput.py:310\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 310\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:1078\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m-> 1078\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m y_hat \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\janav\\Documents\\projects\\iterative-long-term-forecasting\\.venv\\lib\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_cfg = DataConfig(\n",
    "csv_path=csv_path,\n",
    "target_col=\"load\",\n",
    "datetime_col=\"datetime\",\n",
    "batch_size=128, \n",
    "split_ratio=SPLIT_RATIO,\n",
    "horizon=HORIZON\n",
    ")\n",
    "model_cfg = ModelConfig(\n",
    "latent_dim=6,\n",
    "horizon=HORIZON,\n",
    "latent_cfg=LatentForecasterConfig(regressor_params={\n",
    "    \"n_estimators\":100\n",
    "}),\n",
    "optim=OptimConfig(name=\"adam\", lr=0.0001, weight_decay=0),\n",
    "layers=2,\n",
    "hidden=32,\n",
    "dropout=0.01,\n",
    "variational=False\n",
    ")\n",
    "train_cfg = TrainConfig(\n",
    "epochs_ae = 100,\n",
    "loss_fn=\"mse\",\n",
    "early_stop_patience=10\n",
    ")\n",
    "\n",
    "\n",
    "best = random_search_tabular_latent(seed, 50, space, data_cfg, model_cfg, train_cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iterative-long-term-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
